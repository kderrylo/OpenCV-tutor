{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Region Mask\n",
    "- Range Thresholding\n",
    "- Shape Detection (Hough Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np,math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGION MASK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bitwise Not (~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../footage/kim-sejeong.jpg')\n",
    "h,w,c = img.shape\n",
    "\n",
    "masking = np.zeros((h,w)).astype(np.uint8)\n",
    "cv2.circle(masking, (w//2, h//2), 200, (255,255,255), -1)\n",
    "\n",
    "mask_inv = cv2.bitwise_not(img, mask=masking)\n",
    "\n",
    "cv2.imshow(\"mask_inv\", mask_inv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = cv2.imread('../footage/hand.png')\n",
    "gray_hand = cv2.cvtColor(hand, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret,thresh = cv2.threshold(gray_hand, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "masking_inv = cv2.bitwise_not(hand, mask = thresh)\n",
    "\n",
    "cv2.imshow(\"binary_inv\", thresh)\n",
    "cv2.imshow(\"masked\", masking_inv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('../footage/lavender.jpeg')\n",
    "img2 = cv2.resize(img2, (431, 647))\n",
    "cv2.imwrite('../footage/lavender-resized.jpeg',img2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bitwise AND (&)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../footage/kim-sejeong.jpg')\n",
    "img2 = cv2.imread('../footage/lavender-resized.jpeg')\n",
    "h,w,c = img1.shape\n",
    "\n",
    "masking = np.zeros((h,w)).astype(np.uint8)\n",
    "cv2.rectangle(masking, (w//4, h//4), (3*w//4, 3*h//4), (1,0,0), -1)\n",
    "\n",
    "mask_and =  cv2.bitwise_and(img2,img2, mask = masking)\n",
    "\n",
    "cv2.imshow(\"masked\", mask_and)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../footage/kim-sejeong.jpg')\n",
    "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray_img1, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "img2 = cv2.imread('../footage/lavender-resized.jpeg')\n",
    "\n",
    "mask_and = cv2.bitwise_and(img1, img2, mask = thresh)\n",
    "\n",
    "\n",
    "cv2.imshow(\"masked\", mask_and)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bitwise OR ( || )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../footage/kim-sejeong.jpg')\n",
    "img2 = cv2.imread('../footage/lavender-resized.jpeg')\n",
    "h,w,c = img1.shape\n",
    "\n",
    "masking = np.zeros((h,w)).astype(np.uint8)\n",
    "cv2.circle(masking, (w//2, h//2), 200, (255,255,255), -1)\n",
    "\n",
    "mask_and = cv2.bitwise_or(img1, img2, mask=masking)\n",
    "\n",
    "cv2.imshow(\"mask_inv\", mask_and)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../footage/kim-sejeong.jpg')\n",
    "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray_img1, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "img2 = cv2.imread('../footage/lavender-resized.jpeg')\n",
    "\n",
    "masking = cv2.bitwise_or(img1,img2, mask=thresh)\n",
    "\n",
    "cv2.imshow(\"masked\", masking)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANGE THRESHOLDING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HUE\n",
    "- Red : -10 - 10\n",
    "- Orange : 15 - 25\n",
    "- Yellow : 25 - 35\n",
    "- Grenn : 50 - 70\n",
    "- Cyan : 80 - 100\n",
    "- Blue : 110 - 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.array([130,255,255], dtype=np.uint8)\n",
    "bg = np.zeros((200,200,3), dtype=np.uint8)\n",
    "bg[:] = color\n",
    "\n",
    "cv2.imshow('IMAGE', bg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coba kita catch block warna biru, hijau, dan merah pada gambar block.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../footage/blocks.jpg')\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV blue\n",
    "lower_blue = np.array([110,50,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "\n",
    "# HSV green\n",
    "lower_green = np.array([50,50,50])\n",
    "upper_green = np.array([70,255,255])\n",
    "\n",
    "# HSV red\n",
    "lower_red = np.array([-10,50,50])\n",
    "upper_red = np.array([10,255,255])\n",
    "\n",
    "# addition\n",
    "# HSV orange\n",
    "lower_orange = np.array([15,50,50])\n",
    "upper_orange = np.array([25,255,255])\n",
    "\n",
    "# HSV cyan\n",
    "lower_cyan = np.array([80, 50, 50])\n",
    "upper_cyan = np.array([100, 255, 255])\n",
    "\n",
    "# HSV yellow\n",
    "lower_yellow = np.array([25,50,50])\n",
    "upper_yellow = np.array([35,255,255])\n",
    "\n",
    "mask_blue = cv2.inRange(hsv.copy(), lower_blue, upper_blue)\n",
    "mask_green = cv2.inRange(hsv.copy(), lower_green, upper_green)\n",
    "mask_red = cv2.inRange(hsv.copy(), lower_red, upper_red)\n",
    "mask_orange = cv2.inRange(hsv.copy(), lower_orange, upper_orange)\n",
    "mask_cyan = cv2.inRange(hsv.copy(), lower_cyan, upper_cyan)\n",
    "mask_yellow = cv2.inRange(hsv.copy(), lower_yellow, upper_yellow)\n",
    "\n",
    "\n",
    "masking = mask_blue + mask_green + mask_red + mask_orange + mask_cyan + mask_yellow\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask=masking)\n",
    "\n",
    "cv2.imshow(\"res\", res)\n",
    "cv2.imshow(\"masking\", masking)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: detect yellow ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_yellow = np.array([25,50,50])\n",
    "upper_yellow = np.array([35,255,255])\n",
    "\n",
    "video = cv2.VideoCapture('../footage/yellow_ball.mp4')\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        masking_yellow = cv2.inRange(hsv.copy(), lower_yellow, upper_yellow)\n",
    "        res = cv2.bitwise_and(frame, frame, mask=masking_yellow)\n",
    "        \n",
    "        cv2.imshow(\"detected object\", res)\n",
    "        \n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Detection"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAABICAYAAADYiWF/AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAUHSURBVHhe7dwLbuQgDIDh7t6kvf+ZepXddaeWWArBgEN4/J8UTZXJg9jGk3mov/7883agj4+Pr8fPz8+vR9gQN5T8/n48EhMD8HdsU6GhAPc4+k4FgL9jP1MBcA/uVAC4oqkAcEVTgYl+lQyUHN1UZKIwWWzk2zJiBYvj71T4ahnwdfQvamko/7+tscSDuKHkyKbCxHiJ42CNC/HDlePe/jAhXnriIPvJ/kAK3/4ciMaKOx3VVJhMfrhbedXTjnqvizuVw5zeCLzs/ALV+4JxzAe1sxRBnKzcmCzbpbYpXefV86V9U1r2Wd2oa5bziPBcqXV3ab5OaSoneH9///7rOakxtK7LbZNaH7p6vrRvSss+Kxt1vXoeeQz/VqPHUeOItz8zvJqmxmBdJ2SdPHfFeo1ynNTSwjIu9JMYa37Dv2fEZyoP6imM3GS+OqYWY2oR+oi0Jyfzk+dN1dkVmsoAtUmpIccOF9xDYjtyYofnis87usHUNpbtm8roYuhhSVy4jVyXx7XVFExKbdFhb9ypDGCd+JbtdJtUc5GldXJbzg1Y0FQm8OSrvJybhnLtqRjNlJuaF6ytm8qTkzWWS0pcONbtRLxdapsrtduXpMaN82z94zfvSeMhnni58ZW202sLt7Nca+32NXRMu3nqumaLp3U8NBW42THeT17TjPG0jInPVIBJrdqgaSrYiryS4lk0FQCuaCpABnc9aaW4mJqKHOTqQDMGn4J4hjXuqZpKrcN6ik1FkiwfGMlCwtFLG0dcU9TZPqrf/rQmXPbrWbAPaRxKm4iuC//Gmi5/pxInOJXwWYtAxiUo0HFKMc/Vj/DKk2c9UkM/WWJi/vFbLlmeSfTUUhC6T61cXFZXm9fWmLeep0VLPVj3WTXn3jGhqcBNS8y968fzeNTQT5aYmL/96SXH6Fmwn1xeyffauu5UUutmoYXJq8w4pZjHz6e2762p3v1Dpes5kSUmzT9+04MDNbQYU5OfmtqDualIAUjSdaF732PkxArz6eWqLsIa0u3idVf7jzZiLJ6xL9E4956zFJeqOxVNuiwjg9FiREF405iOiK2c44l86vlCqXUn2DXfXR/UnlgId9J43h1XLTA8a9d8F5tKqqHc2eVOR0Pps9q17ZjvYlOJB6SDXC15AMYwf6YizWTFVzkZM17ujMWucZZ6X/XavMctx7PM/63/R62wBmKEOMlasKnC1THn9glZr0/PlXL1nEXv/jNrvbZUnvRYqedEbp+QdSx6rpSr53Ks+1R9+4N2mpBwCYtF18Xi9aXjYA4n55um8qCweKxa9glJQaYW5HlN5JXzLftYx0JTGSRXmL1Fo0qFokWRWoQ+wofE89R8b99UJHilBIwkYwmXHch13FmkM2itozDXLfvPQMZdk1/uVAaSxMw2+VYt9BWcmm+ayiBhMrXYZJlhUs9W+LOqydcu+Zbx1mwvjmgqsyRzNi0FE/M4xkpWrqXaXLXmljuVgeJifHJCPnnu1Vkby8r57hnr9j9+C82QVHlU4VjC9SrePlR6LiV37lZyPI/jrEhjeRXrOEfhtuF6FW8fKj2Xkjt3ie5Xs0+IpoJmxBMpR739kQmQ6/aoQ0NBznGfqdBY+tFQcIUPagG4OrKpcLfSjrsUlBx7p0JjqUdDgcXRb39oLHY0FFgd9ZUygPvxQS0AVzQVAK5oKgBc0VQAuKKpAHBFUwHgiqYCwBVNBYCjt7e/IdEXiDdm1IEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "road = cv2.imread('../footage/road.jpg')\n",
    "\n",
    "gray_road = cv2.cvtColor(road, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edges = cv2.Canny(gray_road, 50,200)\n",
    "\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180 , 100, None, 0,0)\n",
    "\n",
    "for line in lines:\n",
    "    rho = line[0][0]\n",
    "    theta = line[0][1]\n",
    "    a = math.cos(theta)\n",
    "    b = math.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1,y1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "    x2,y2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "    cv2.line(road, (x1,y1), (x2,y2), (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "road1 = cv2.imread('../footage/road.jpg')\n",
    "cv2.imshow('ori', road1)\n",
    "cv2.imshow('canny', edges)\n",
    "cv2.imshow('HoughLine', road)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=50, maxLineGap=30)\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(road, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "cv2.imshow(\"res\", road)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = cv2.imread('../footage/eye.jpg')\n",
    "h,w,c = eye.shape\n",
    "\n",
    "gray_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray_eye, (5,5), 0,0)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1,h/64, param1=200, param2=17, minRadius=21, maxRadius=30)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))[0]\n",
    "    for i in circles:\n",
    "        cv2.circle(eye, (i[0], i[1]), i[2], (0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"output\", eye)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0553d4ce217247116af3d8bd9f72185f3b0a33ff55f09110a8f4dadfab291d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
